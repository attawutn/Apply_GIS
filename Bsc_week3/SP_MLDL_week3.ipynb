{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\t\n",
    "87613259\tScripting Language\n",
    "=======================================\n",
    "Credit : Patrick Gray (patrick.c.gray at duke) - https://github.com/patrickcgray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset\n",
    "#### Opening the images\n",
    "Our first step is to recall our previous chapter's lessons and import the things we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2201, 2629)\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import os # we need os to do some basic file operations\n",
    "\n",
    "sentinal_fp = \"sentinel-2/\"\n",
    "# find every file in the sentinal_fp directory\n",
    "sentinal_band_paths = [os.path.join(sentinal_fp, f) for f in os.listdir(sentinal_fp) if os.path.isfile(os.path.join(sentinal_fp, f))]\n",
    "sentinal_band_paths.sort()\n",
    "\n",
    "# create a products directory within the data dir which won't be uploaded to Github\n",
    "img_dir = 'products/'\n",
    "\n",
    "# check to see if the dir it exists, if not, create it\n",
    "if not os.path.exists(img_dir):\n",
    "    os.makedirs(img_dir)\n",
    "\n",
    "# filepath for image we're writing out\n",
    "img_fp = img_dir + 'sentinel_bands.tif'\n",
    "\n",
    "# Read metadata of first file and assume all other bands are the same\n",
    "with rasterio.open(sentinal_band_paths[0]) as src0:\n",
    "    meta = src0.meta\n",
    "\n",
    "# Update metadata to reflect the number of layers\n",
    "meta.update(count = len(sentinal_band_paths))\n",
    "\n",
    "# Read each layer and write it to stack\n",
    "with rasterio.open(img_fp, 'w', **meta) as dst:\n",
    "    for id, layer in enumerate(sentinal_band_paths, start=1):\n",
    "        with rasterio.open(layer) as src1:\n",
    "            dst.write_band(id, src1.read(1))\n",
    "            \n",
    "full_dataset = rasterio.open(img_fp)\n",
    "img_rows, img_cols = full_dataset.shape\n",
    "img_bands = full_dataset.count\n",
    "print(full_dataset.shape) # dimensions\n",
    "print(full_dataset.count) # bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Attawut\\Anaconda3\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapefile = gpd.read_file('training_data//rcr_landcover.shp')\n",
    "shapefile = shapefile.to_crs({'init': 'epsg:4326'})\n",
    "len(shapefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to extract the geometry of each feature in the shapefile in GeoJSON format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this generates a list of shapely geometries\n",
    "geoms = shapefile.geometry.values \n",
    "# let's grab a single shapely geometry to check\n",
    "geometry = geoms[0] \n",
    "# transform to GeoJSON format\n",
    "from shapely.geometry import mapping\n",
    "feature = [mapping(geometry)] # can also do this using polygon.__geo_interface__\n",
    "out_image, out_transform = mask(full_dataset, feature, crop=True)\n",
    "out_image.shape\n",
    "full_dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Training Data for `scikit-learn`\n",
    "\n",
    "Now let's do it for all features in the shapefile and create an array `X` that has all the pixels and an array `y` that has all the training labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([], dtype=np.int8).reshape(0,8) # pixels for training\n",
    "y = np.array([], dtype=np.string_) # labels for training\n",
    "\n",
    "# extract the raster values within the polygon \n",
    "with rasterio.open(img_fp) as src:\n",
    "    band_count = src.count\n",
    "    for index, geom in enumerate(geoms):\n",
    "        feature = [mapping(geom)]\n",
    "\n",
    "        # the mask function returns an array of the raster pixels within this feature\n",
    "        out_image, out_transform = mask(src, feature, crop=True) \n",
    "        # eliminate all the pixels with 0 values for all 8 bands - AKA not actually part of the shapefile\n",
    "        out_image_trimmed = out_image[:,~np.all(out_image == 0, axis=0)]\n",
    "        # eliminate all the pixels with 255 values for all 8 bands - AKA not actually part of the shapefile\n",
    "        out_image_trimmed = out_image_trimmed[:,~np.all(out_image_trimmed == 255, axis=0)]\n",
    "        # reshape the array to [pixel count, bands]\n",
    "        out_image_reshaped = out_image_trimmed.reshape(-1, band_count)\n",
    "        # append the labels to the y array\n",
    "        y = np.append(y,[shapefile[\"Classname\"][index]] * out_image_reshaped.shape[0]) \n",
    "        # stack the pizels onto the pixel array\n",
    "        X = np.vstack((X,out_image_reshaped))        \n",
    "\n",
    "# What are our classification labels?\n",
    "labels = np.unique(shapefile[\"Classname\"])\n",
    "\n",
    "def str_class_to_int(class_array):\n",
    "    class_array[class_array == 'Subtidal Haline'] = 0\n",
    "    class_array[class_array == 'WetSand'] = 1\n",
    "    class_array[class_array == 'Emergent Wetland'] = 2\n",
    "    class_array[class_array == 'Sand'] = 3\n",
    "    class_array[class_array == 'Herbaceous'] = 4\n",
    "    class_array[class_array == 'Forested Wetland'] = 5\n",
    "    return(class_array.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Split Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training the Classifier**\n",
    "Now that we have our X matrix of feature inputs (the spectral bands) and our y array (the labels), we can train our model.\n",
    "# Quiz 1 Random Forest\n",
    "ให้ลองเปลี่ยน Classifier สามารถดูรายละเอียดได้ที่ https://scikit-learn.org/stable/modules/classes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [180, 418]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-db098c4e8024>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mpscore_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \"\"\"\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    256\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [180, 418]"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "pscore = metrics.accuracy_score(y_test, y_train)\n",
    "pscore_train = metrics.accuracy_score(y_train, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is that simple to train a classifier in `scikit-learn`! The hard part is often validation and interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.plot import show\n",
    "from rasterio.plot import show_hist\n",
    "from rasterio.windows import Window\n",
    "from rasterio.plot import reshape_as_raster, reshape_as_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with rasterio.open(img_fp) as src:\n",
    "    # may need to reduce this image size if your kernel crashes, takes a lot of memory\n",
    "    img = src.read()[:, 150:600, 250:1400]\n",
    "\n",
    "# Take our full image and reshape into long 2d array (nrow * ncol, nband) for classification\n",
    "print(img.shape)\n",
    "reshaped_img = reshape_as_image(img)\n",
    "print(reshaped_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can predict for each pixel in our image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_prediction = clf.predict(reshaped_img.reshape(-1, 8))\n",
    "\n",
    "# Reshape our classification map back into a 2D matrix so we can visualize it\n",
    "class_prediction = class_prediction.reshape(reshaped_img[:, :, 0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our shapefile came with the labels as strings we want to convert them to a numpy array with ints using the helper function we made earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_prediction = str_class_to_int(class_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visualize it!\n",
    "\n",
    "First we'll make a colormap so we can visualize the classes, which are just encoded as integers, in more logical colors. Don't worry too much if this code is confusing! It can be a little clunky to specify colormaps for `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_stretch(image, index):\n",
    "    colors = image[:, :, index].astype(np.float64)\n",
    "    for b in range(colors.shape[2]):\n",
    "        colors[:, :, b] = rasterio.plot.adjust_band(colors[:, :, b])\n",
    "    return colors\n",
    "    \n",
    "# find the highest pixel value in the prediction image\n",
    "n = int(np.max(class_prediction))\n",
    "\n",
    "# next setup a colormap for our map\n",
    "colors = dict((\n",
    "    (0, (48, 156, 214, 255)),   # Blue - Water\n",
    "    (1, (139,69,19, 255)),      # Brown - WetSand\n",
    "    (2, (96, 19, 134, 255)),    # Purple - Emergent Wetland\n",
    "    (3, (244, 164, 96, 255)),   # Tan - Sand\n",
    "    (4, (206, 224, 196, 255)),  # Lime - Herbaceous\n",
    "    (5, (34, 139, 34, 255)),    # Forest Green - Forest \n",
    "))\n",
    "\n",
    "# Put 0 - 255 as float 0 - 1\n",
    "for k in colors:\n",
    "    v = colors[k]\n",
    "    _v = [_v / 255.0 for _v in v]\n",
    "    colors[k] = _v\n",
    "    \n",
    "index_colors = [colors[key] if key in colors else \n",
    "                (255, 255, 255, 0) for key in range(0, n+1)]\n",
    "\n",
    "cmap = plt.matplotlib.colors.ListedColormap(index_colors, 'Classification', n+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now show the classified map next to the RGB image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,1,figsize=(10,7))\n",
    "\n",
    "img_stretched = color_stretch(reshaped_img, [4, 3, 2])\n",
    "axs[0].imshow(img_stretched)\n",
    "\n",
    "axs[1].imshow(class_prediction, cmap=cmap, interpolation='none')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This looks pretty good!\n",
    "\n",
    "Let's generate a map of Normalized Difference Water Index (NDWI) and NDVI just to compare with out output map.\n",
    "\n",
    "NDWI is similar to NDVI but for identifying water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(img_fp) as src:\n",
    "    green_band = src.read(3)\n",
    "    red_band = src.read(4)\n",
    "    nir_band = src.read(8)\n",
    "    \n",
    "ndwi = (green_band.astype(float) - nir_band.astype(float)) / (green_band.astype(float) + nir_band.astype(float))\n",
    "ndvi = (nir_band.astype(float) - red_band.astype(float)) / (red_band.astype(float) + nir_band.astype(float))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset them to our area of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndwi = ndwi[150:600, 250:1400]\n",
    "ndvi = ndvi[150:600, 250:1400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display all four maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2,figsize=(15,7))\n",
    "\n",
    "img_stretched = color_stretch(reshaped_img, [3, 2, 1])\n",
    "axs[0,0].imshow(img_stretched)\n",
    "\n",
    "axs[0,1].imshow(class_prediction, cmap=cmap, interpolation='none')\n",
    "\n",
    "nwdi_plot = axs[1,0].imshow(ndwi, cmap=\"RdYlGn\")\n",
    "axs[1,0].set_title(\"NDWI\")\n",
    "fig.colorbar(nwdi_plot, ax=axs[1,0])\n",
    "\n",
    "ndvi_plot = axs[1,1].imshow(ndvi, cmap=\"RdYlGn\")\n",
    "axs[1,1].set_title(\"NDVI\")\n",
    "fig.colorbar(ndvi_plot, ax=axs[1,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty good! Areas that are high on the NDWI ratio are generally classified as water and areas high on NDVI are forest and herbaceous. It does seem like the wetland areas (e.g. the bottom right island complex) aren't being picked up so it might be worth experimenting with other algorithms!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the Duke Marine Lab and the tip of the Rachel Carson Reserve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize=(15,15))\n",
    "\n",
    "img_stretched = color_stretch(reshaped_img, [3, 2, 1])\n",
    "axs[0].imshow(img_stretched[0:180, 160:350])\n",
    "\n",
    "axs[1].imshow(class_prediction[0:180, 160:350], cmap=cmap, interpolation='none')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This actually doesn't look half bad! Land cover mapping is a complex problem and one where there are many approaches and tools for improving a map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing an Unsupervised Classification Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also try a unsupervised classification algorithm, k-means clustering, in the scikit-learn library ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html))\n",
    "\n",
    "K-means ([wikipedia page](https://en.wikipedia.org/wiki/K-means_clustering)) aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 2\n",
    "ลองเปลี่ยนจำนวน Class ในการประมวลผล K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "bands, rows, cols = img.shape\n",
    "\n",
    "k = 10 # num of clusters\n",
    "\n",
    "kmeans_predictions = KMeans(n_clusters=k, random_state=0).fit(reshaped_img.reshape(-1, 8))\n",
    "\n",
    "kmeans_predictions_2d = kmeans_predictions.labels_.reshape(rows, cols)\n",
    "\n",
    "# Now show the classmap next to the image\n",
    "fig, axs = plt.subplots(1,2,figsize=(15,8))\n",
    "\n",
    "img_stretched = color_stretch(reshaped_img, [3, 2, 1])\n",
    "axs[0].imshow(img_stretched)\n",
    "\n",
    "axs[1].imshow(kmeans_predictions_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize=(15,15))\n",
    "\n",
    "img_stretched = color_stretch(reshaped_img, [3, 2, 1])\n",
    "axs[0].imshow(img_stretched[0:180, 160:350])\n",
    "\n",
    "axs[1].imshow(kmeans_predictions_2d[0:180, 160:350], cmap=cmap, interpolation='none')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
